{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir Dataset fornecido em formato Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import join,basename\n",
    "from tqdm import tqdm\n",
    "from os import system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O nome do tipo de entidade para cada dataset\n",
    "DATASET_NAME_2_ENTITY_TYPE=\\\n",
    "{\n",
    "    'BC2GM':'DRUG',\n",
    "    'BC4CHEMD':'CHEMICAL',\n",
    "    'BC5CDR-disease':'DISEASE',\n",
    "    'BC5CDR-chem':'CHEMICAL',\n",
    "    'JNLPBA':'DRUG',\n",
    "    'linnaeus':'SPECIES',\n",
    "    'NCBI-disease':'DISEASE',\n",
    "    's800':'SPECIES',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_iob_format(input_file, output_file, entity_type):\n",
    "    # Abrimos o arquivo de anotação base \n",
    "    with open(input_file,'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sents=[] # Lista de sentenças \n",
    "    sent=[] # Uma sentença\n",
    "    \n",
    "    # Iteramos ao longo do documento \n",
    "    for line in lines:\n",
    "        line=line.strip()\n",
    "        \n",
    "        if line:\n",
    "            # Para cada linha removemos o quebre de linha e separamos a palavra do tag\n",
    "            word,tag=line.replace('\\n','').split('\\t')\n",
    "            \n",
    "            # Anotamos o complemento I -> I->ENTITY e B -> B-entity\n",
    "            if tag in ['I','B']:\n",
    "                tag=f'{tag}-{entity_type}'\n",
    "                \n",
    "            # Armazenamos a palavra e o tag no formato IOB\n",
    "            sent.append(f'{word}'+'|''|'+f'{tag}')\n",
    "        else:\n",
    "            \n",
    "            # se a linha estiver vacia então indica o final da linha. \n",
    "            # Se armazena a sentença e se limpa \"sent\" par coletar a seguinte linha\n",
    "            sents.append(sent)\n",
    "            sent=[]\n",
    "\n",
    "    # Juntamos todas as sentenças por espaço ' ' e todas as linhas por quebre de linha '\\n'\n",
    "    sents_content = '\\n'.join([' '.join(sent) for sent in sents])\n",
    "\n",
    "    # Salvamos o formato IOB\n",
    "    with open(output_file,'w+') as file:\n",
    "        file.write(sents_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pocessamos todos os arquivos usando CLI: \n",
    "```bash\n",
    "python -m spacy convert ...\n",
    "```\n",
    "\n",
    "Documentação: [https://spacy.io/api/cli#convert](https://spacy.io/api/cli#convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = glob('..\\\\NERdata\\\\*')\n",
    "for folder_path in tqdm(folder_paths, total=len(folder_paths)):\n",
    "    \n",
    "    dataset_name = basename(folder_path)\n",
    "    \n",
    "    entity_type = DATASET_NAME_2_ENTITY_TYPE[dataset_name]\n",
    "    \n",
    "    for input_file in glob(join(folder_path,'*.tsv')):\n",
    "        \n",
    "        iob_file = input_file.replace('.tsv','.iob')\n",
    "        \n",
    "        convert_to_iob_format(input_file, iob_file, entity_type)\n",
    "    \n",
    "        system(f'python -m spacy convert -c iob -s -n 10 -b en_core_web_sm {iob_file} {folder_path}') #v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do dataset BC2GM (Usar máquina com GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializar configuração de treinamento: [https://spacy.io/usage/training#config](https://spacy.io/usage/training#config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy train config.cfg --verbose --paths.train ./NERdata/BC2GM/train.spacy --paths.dev ./NERdata/BC2GM/devel.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "text=\\\n",
    "\"Immunohistochemical staining was positive for S - 100 in all 9 cases stained , positive for HMB - 45 \" +\\\n",
    "\"in\t9 ( 90 % ) of 10 , and negative for cytokeratin in all 9 cases in which myxoid melanoma remained\" +\\\n",
    "\"in the\tblock after previous sections .\"\n",
    "\n",
    "model_path=R\".\\output\\model-best\"\n",
    "nlp1 = spacy.load(model_path) #load the best model\n",
    "doc = nlp1(text) # input sample text\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
